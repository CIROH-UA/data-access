{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b584892",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "This Jupyter notebook is developed to show case the use of JSON header files for faster data access to NWM files. Here's a brief overview of the imported modules:\n",
    "\n",
    "- `joblib`: Used for parallel processing and efficient caching.\n",
    "- `numpy`: A fundamental library for numerical operations.\n",
    "- `xarray`: A library for working with labeled multi-dimensional arrays, often used in scientific data analysis.\n",
    "- `fsspec`: Provides a common interface for working with various filesystem-like protocols.\n",
    "- `ujson`: A fast JSON encoder and decoder for handling JSON data.\n",
    "- `matplotlib.pyplot`: Used for creating data visualizations.\n",
    "- `psutil`: Provides information on system resource utilization.\n",
    "- `concurrent.futures`: A module for asynchronously executing functions using threads or processes.\n",
    "- `multiprocessing`: A library for parallel and concurrent computing.\n",
    "- `urlgennwm`: An external library/module for generating URLs specific to the NWM (National Water Model).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2171bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import ujson\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import urlgennwm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9816c033",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet retrieves and calculates system information, including the number of CPU cores and available memory in gigabytes (GB). It also computes a memory limit per worker process based on available resources. These metrics are essential for optimizing and parallelizing computational tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd81bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of available CPU cores\n",
    "num_cores = psutil.cpu_count(logical=False)  # Use logical=True for hyperthreading\n",
    "\n",
    "# Calculate the available memory in GB\n",
    "available_memory_gb = psutil.virtual_memory().available / (1024 ** 3)  # Bytes to GB\n",
    "\n",
    "# Calculate a memory limit per worker based on available memory\n",
    "# Adjust this factor based on your memory usage requirements\n",
    "memory_per_worker_gb = available_memory_gb / num_cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ee349",
   "metadata": {},
   "source": [
    "This code defines a set of functions for working with remote datasets in JSON format. It includes functions to load remote JSON content, open datasets from JSON, select streamflow data, and select time values. The `process_file` function combines these operations to process a single file for a given feature ID, making it useful for retrieving and working with specific data from remote sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7807ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load remote JSON content\n",
    "def load_remote_json(file_url):\n",
    "    of = fsspec.open(file_url)\n",
    "    with of as f:\n",
    "        return ujson.load(f)\n",
    "\n",
    "# Define a function to load a remote dataset from JSON content\n",
    "def load_remote_ds(json_obj):\n",
    "    backend_args = {\n",
    "        \"consolidated\": False,\n",
    "        \"storage_options\": {\n",
    "            \"fo\": json_obj,\n",
    "        },\n",
    "    }\n",
    "    return xr.open_dataset(\"reference://\", engine=\"zarr\", backend_kwargs=backend_args)\n",
    "\n",
    "# Define a function to select streamflow data from a dataset\n",
    "def select_flow(ds, feature_id):\n",
    "    cords = ds.streamflow.sel(feature_id=feature_id)\n",
    "    return cords.values\n",
    "\n",
    "# Define a function to select time\n",
    "def select_time(ds):\n",
    "    dstime = ds.time\n",
    "    return dstime.values\n",
    "\n",
    "# Define a function to process a single file for a given feature ID\n",
    "def process_file(file_url, feature_id):\n",
    "    json_obj = load_remote_json(file_url)\n",
    "    ds = load_remote_ds(json_obj)\n",
    "    streamflow_value = select_flow(ds, feature_id)\n",
    "    time_value = select_time(ds)\n",
    "    return streamflow_value, time_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196c442",
   "metadata": {},
   "source": [
    "\n",
    "This code defines a list of feature IDs, which are typically used as identifiers for specific geographic or data features. In this case, the list includes feature IDs `8153461`, `8153027`, and `18210860`, representing specific features of interest. These feature IDs are used in subsequent data retrieval. Feature IDs could for different locations could be found at https://water.noaa.gov/map#forecast-chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of feature IDs\n",
    "feature_ids = [8153461, 8153027, 18210860]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5cb989",
   "metadata": {},
   "source": [
    "This code sets input variables `start_date`, `end_date`, and `fcst_cycle` to specify the date and forecast cycle parameters. It then calls the `urlgennwm.generate_urls` function,  to generate a list of URLs for accessing data related to the National Water Model (NWM) for the specified date and forecast cycle. These URLs are used to retrieve specific NWM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271445a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting input variables to generate NWM JSON header urls\n",
    "start_date = \"202201120000\"\n",
    "end_date   = \"202201130000\"\n",
    "fcst_cycle = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "urlgennwm.generate_urls(start_date, end_date, fcst_cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e22abd",
   "metadata": {},
   "source": [
    "This code snippet initializes an empty list called `files` to store URLs. It then specifies the name of a file, \"filenamelist.txt,\" which contains a list of URLs. The code opens this file in read mode, reads the URLs line by line, removes leading and trailing whitespace from each line, and appends each URL to the `files` list. Finally, it initializes an empty dictionary called `extracted_values_dict`,  intended to store extracted values associated with specific feature IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the URLs\n",
    "files = []\n",
    "\n",
    "# Define the name of the file containing the URLs\n",
    "filename = \"filenamelist.txt\"\n",
    "\n",
    "# Open the file in read mode and read the URLs line by line\n",
    "with open(filename, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Remove leading and trailing whitespace and append the URL to the list\n",
    "        url = line.strip()\n",
    "        files.append(url)\n",
    "# Create a dictionary to store the extracted values for each feature ID\n",
    "extracted_values_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda34422",
   "metadata": {},
   "source": [
    "This code snippet utilizes the `joblib` library to create a parallel processing pool using threading for dynamic settings. It processes a list of `files` using the `process_file` function in parallel, passing each `file_url` and the `feature_ids` list as arguments. The results are stored in `result_values` and sorted based on the first element of each result tuple. The extracted streamflow values are then stored in the `Streamflow` list, and the associated timestamps are stored in the `Timestamp` list, which can be further used for analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c06fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Parallel processing pool using joblib with dynamic settings\n",
    "with joblib.parallel_backend(\"threading\", n_jobs=num_cores):  # Use threads for parallel processing\n",
    "    result_values = joblib.Parallel()(joblib.delayed(process_file)(file_url, feature_ids) for file_url in files)\n",
    "result_values = sorted(result_values, key=lambda x: x[1][0])\n",
    "Streamflow = [item[0] for item in result_values]\n",
    "Timestamp = [item[1] for item in result_values]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527fc611",
   "metadata": {},
   "source": [
    "This code snippet creates separate plots for each feature ID in the `feature_ids` list. For each feature ID, it plots the time series of the extracted streamflow values using Matplotlib. The streamflow values are stored in the `Streamflow` list, and each plot is labeled with the corresponding feature ID. The x-axis represents time in hours, and the y-axis represents streamflow values. Finally, the code displays all the separate plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6770400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate plots for each feature ID\n",
    "    # Plot the time series of the extracted streamflow values for the current feature ID using Matplotlib\n",
    "plt.figure()\n",
    "plt.plot(Streamflow, label=[f\"Feature ID {feature_id}\" for feature_id in feature_ids])\n",
    "#plt.xlabel(f\"Time(hours after {min(Timestamp)})\")\n",
    "plt.xlabel(\"Time(hours)\")\n",
    "plt.ylabel(\"Streamflow\")\n",
    "plt.title(f\"Streamflow Time Series\")\n",
    "plt.legend()\n",
    "# Show all the separate plots\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
